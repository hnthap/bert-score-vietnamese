{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "device: cuda\n",
      "device name: NVIDIA GeForce RTX 3050 Laptop GPU\n",
      "garbage collector collected 1934 objects\n"
     ]
    }
   ],
   "source": [
    "import gc\n",
    "import time\n",
    "\n",
    "import torch\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print('device:', device)\n",
    "if torch.cuda.is_available():\n",
    "    print('device name:', torch.cuda.get_device_name(device))\n",
    "\n",
    "def collect(*, verbose=True):\n",
    "    if verbose:\n",
    "        print('garbage collector collected %d objects' % gc.collect())\n",
    "    else:\n",
    "        gc.collect()\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.empty_cache()\n",
    "        torch.cuda.reset_peak_memory_stats()\n",
    "\n",
    "collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Hello, **World**!"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import display, Markdown\n",
    "\n",
    "display(Markdown('Hello, **World**!'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "garbage collector collected 85 objects\n"
     ]
    }
   ],
   "source": [
    "from transformers import (\n",
    "    MBartForConditionalGeneration,\n",
    "    MBart50TokenizerFast,\n",
    ")\n",
    "\n",
    "model_name = 'facebook/mbart-large-50-many-to-many-mmt'\n",
    "\n",
    "mbart_tokenizer = MBart50TokenizerFast.from_pretrained(model_name, device=device)\n",
    "mbart_model = MBartForConditionalGeneration.from_pretrained(model_name)\n",
    "mbart_model.to(device)\n",
    "collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def translate_article(article, source_lang, target_lang, *, verbose=False, device=device):\n",
    "    global mbart_tokenizer, mbart_model\n",
    "    mbart_tokenizer.src_lang = source_lang\n",
    "    encoded = mbart_tokenizer(article, return_tensors='pt')\n",
    "    encoded.to(device)\n",
    "    if verbose:\n",
    "        print('Tokenized article:')\n",
    "        for key, value in encoded.items():\n",
    "            print('%s: %s, %s, %s' % (key, str(value.size()), str(value.dtype), str(value.device)))\n",
    "    tokens = mbart_model.generate(\n",
    "        **encoded,\n",
    "        forced_bos_token_id=mbart_tokenizer.lang_code_to_id[target_lang],\n",
    "    )\n",
    "    translated_article = mbart_tokenizer.batch_decode(tokens, skip_special_tokens=True)\n",
    "    return translated_article[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenized article:\n",
      "input_ids: torch.Size([1, 97]), torch.int64, cuda:0\n",
      "attention_mask: torch.Size([1, 97]), torch.int64, cuda:0\n",
      "Calculation duration: 2.8569 seconds\n",
      "garbage collector collected 11 objects\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "\n",
       "----\n",
       "**⚜️ Original article**\n",
       "\n",
       "\n",
       "Đồng hồ sắp đánh tám giờ. Học trò tấp nập đi học, lũ năm lũ ba, tay cắp sách vừa đi vừa chuyện trò vui vẻ.\n",
       "\n",
       "Đến trường, ai nấy vào học. Các lớp học đều rộng rãi, mát mẻ.\n",
       "\n",
       "Thầy giáo hết lòng dạy các cậu, mà các cậu học hành rất chăm chỉ.\n",
       "\n",
       "Sự học hành cần lắm. Ta phải rủ nhau đi học. Có học mới khôn được.\n",
       "\n",
       "\n",
       "----\n",
       "**⚜️ Translated article**\n",
       "\n",
       "The clock is eight o'clock. Students are rushing to school, fifth-graders, third-graders, they're grabbing books and they're walking and they're having a nice conversation. They're coming to school, everybody's eager to come. The classrooms are big, they're cool. The teacher's really teaching you, and you're learning hard. You've got to talk to each other about going to school. You've got to learn hard.\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "article = '''\n",
    "Đồng hồ sắp đánh tám giờ. Học trò tấp nập đi học, lũ năm lũ ba, tay cắp sách vừa đi vừa chuyện trò vui vẻ.\n",
    "\n",
    "Đến trường, ai nấy vào học. Các lớp học đều rộng rãi, mát mẻ.\n",
    "\n",
    "Thầy giáo hết lòng dạy các cậu, mà các cậu học hành rất chăm chỉ.\n",
    "\n",
    "Sự học hành cần lắm. Ta phải rủ nhau đi học. Có học mới khôn được.\n",
    "'''\n",
    "\n",
    "now = time.time_ns()\n",
    "with torch.no_grad():\n",
    "    translated_article = translate_article(article, 'vi_VN', 'en_XX', verbose=True)\n",
    "delta = time.time_ns() - now\n",
    "print('Calculation duration: %.4f seconds' % (delta / (10 ** 9)))\n",
    "\n",
    "collect()\n",
    "\n",
    "display(Markdown(\n",
    "'''\n",
    "----\n",
    "**⚜️ Original article**\n",
    "\n",
    "%s\n",
    "\n",
    "----\n",
    "**⚜️ Translated article**\n",
    "\n",
    "%s\n",
    "''' % (article, translated_article)\n",
    "))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bert-score",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
